{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ":ext FlexibleContexts\n",
    ":ext OverloadedLists\n",
    "\n",
    "import           Control.Monad          ( forM_\n",
    "                                        , when\n",
    "                                        )\n",
    "import           Control.Monad.IO.Class ( liftIO )\n",
    "import           Data.Int               ( Int32\n",
    "                                        , Int64\n",
    "                                        )\n",
    "import           Data.List              ( genericLength )\n",
    "import qualified Data.Text.IO as T\n",
    "import qualified Data.Vector  as V\n",
    "\n",
    "import qualified TensorFlow.Core     as TF\n",
    "import qualified TensorFlow.Ops      as TF hiding ( initializedVariable, zeroInitializedVariable )\n",
    "import qualified TensorFlow.Variable as TF\n",
    "import qualified TensorFlow.Minimize as TF\n",
    "\n",
    "import TensorFlow.Examples.MNIST.InputData\n",
    "import TensorFlow.Examples.MNIST.Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numPixels = 28*28 :: Int64\n",
    "numLabels = 10    :: Int64\n",
    "\n",
    "-- | Create tensor with random values where the stddev depends on the width.\n",
    "randomParam :: Int64 -> TF.Shape -> TF.Build (TF.Tensor TF.Build Float)\n",
    "randomParam width (TF.Shape shape) = (`TF.mul` stddev) <$> TF.truncatedNormal (TF.vector shape)\n",
    "  where\n",
    "    stddev = TF.scalar (1 / sqrt (fromIntegral width))\n",
    "\n",
    "-- Types must match due to model structure.\n",
    "type LabelType = Int32\n",
    "\n",
    "data Model = Model {\n",
    "      train :: TF.TensorData Float  -- ^ images\n",
    "            -> TF.TensorData LabelType\n",
    "            -> TF.Session ()\n",
    "    , infer :: TF.TensorData Float  -- ^ images\n",
    "            -> TF.Session (V.Vector LabelType)  -- ^ predictions\n",
    "    , errorRate :: TF.TensorData Float  -- ^ images\n",
    "                -> TF.TensorData LabelType\n",
    "                -> TF.Session Float\n",
    "    }\n",
    "\n",
    "createModel :: TF.Build Model\n",
    "createModel = do\n",
    "    -- Use -1 batch size to support variable sized batches.\n",
    "    let batchSize = -1\n",
    "    \n",
    "    -- Inputs.\n",
    "    images <- TF.placeholder [batchSize, numPixels]\n",
    "    \n",
    "    -- Hidden layer.\n",
    "    let numUnits = 500\n",
    "    \n",
    "    hiddenWeights <- TF.initializedVariable =<< randomParam numPixels [numPixels, numUnits]\n",
    "    hiddenBiases  <- TF.zeroInitializedVariable [numUnits]\n",
    "    let hiddenZ = (images `TF.matMul` TF.readValue hiddenWeights)\n",
    "                  `TF.add` TF.readValue hiddenBiases\n",
    "    let hidden = TF.relu hiddenZ\n",
    "    \n",
    "    -- Logits.\n",
    "    logitWeights <- TF.initializedVariable =<< randomParam numUnits [numUnits, numLabels]\n",
    "    logitBiases  <- TF.zeroInitializedVariable [numLabels]\n",
    "    let logits = (hidden `TF.matMul` TF.readValue logitWeights)\n",
    "                 `TF.add` TF.readValue logitBiases\n",
    "    predict <- TF.render $ TF.cast $\n",
    "               TF.argMax (TF.softmax logits) (TF.scalar (1 :: LabelType))\n",
    "\n",
    "    -- Create training action.\n",
    "    labels <- TF.placeholder [batchSize]\n",
    "    let labelVecs = TF.oneHot labels (fromIntegral numLabels) 1 0\n",
    "        loss      = reduceMean $ fst $ TF.softmaxCrossEntropyWithLogits logits labelVecs\n",
    "        params    = [hiddenWeights, hiddenBiases, logitWeights, logitBiases]\n",
    "    trainStep <- TF.minimizeWith TF.adam loss params\n",
    "\n",
    "    let correctPredictions = TF.equal predict labels\n",
    "    errorRateTensor <- TF.render $ 1 - reduceMean (TF.cast correctPredictions)\n",
    "\n",
    "    return Model {\n",
    "          train = \\imFeed lFeed -> TF.runWithFeeds_ [\n",
    "                TF.feed images imFeed\n",
    "              , TF.feed labels lFeed\n",
    "              ] trainStep\n",
    "        , infer = \\imFeed -> TF.runWithFeeds [TF.feed images imFeed] predict\n",
    "        , errorRate = \\imFeed lFeed -> TF.unScalar <$> TF.runWithFeeds [\n",
    "                TF.feed images imFeed\n",
    "              , TF.feed labels lFeed\n",
    "              ] errorRateTensor\n",
    "        }\n",
    "\n",
    "main :: IO ()\n",
    "main = TF.runSession $ do\n",
    "    -- Read training and test data.\n",
    "    trainingImages <- liftIO (readMNISTSamples =<< trainingImageData)\n",
    "    trainingLabels <- liftIO (readMNISTLabels  =<< trainingLabelData)\n",
    "    testImages     <- liftIO (readMNISTSamples =<< testImageData)\n",
    "    testLabels     <- liftIO (readMNISTLabels  =<< testLabelData)\n",
    "\n",
    "    -- Create the model.\n",
    "    model <- TF.build createModel\n",
    "\n",
    "    -- Functions for generating batches.\n",
    "    let encodeImageBatch xs =\n",
    "          TF.encodeTensorData [genericLength xs, numPixels]\n",
    "                              (fromIntegral <$> mconcat xs)\n",
    "        encodeLabelBatch xs =\n",
    "          TF.encodeTensorData [genericLength xs]\n",
    "                              (fromIntegral <$> V.fromList xs)\n",
    "\n",
    "        batchSize = 100\n",
    "        selectBatch i xs = take batchSize $ drop (i * batchSize) (cycle xs)\n",
    "\n",
    "    -- Train.\n",
    "    forM_ ([0..1000] :: [Int]) $ \\i -> do\n",
    "        let images = encodeImageBatch (selectBatch i trainingImages)\n",
    "            labels = encodeLabelBatch (selectBatch i trainingLabels)\n",
    "        train model images labels\n",
    "        when (i `mod` 100 == 0) $ do\n",
    "            err <- errorRate model images labels\n",
    "            liftIO . putStrLn $ \"training error \" ++ show (err * 100)\n",
    "    liftIO . putStrLn $ \"\"\n",
    "\n",
    "    -- Test.\n",
    "    testErr <- errorRate model (encodeImageBatch testImages)\n",
    "                               (encodeLabelBatch testLabels)\n",
    "    liftIO . putStrLn $ \"test error \" ++ show (testErr * 100)\n",
    "\n",
    "    -- Show some predictions.\n",
    "    testPreds <- infer model (encodeImageBatch testImages)\n",
    "    liftIO $ forM_ ([0..3] :: [Int]) $ \\i -> do\n",
    "        putStrLn \"\"\n",
    "        T.putStrLn $ drawMNIST $ testImages !! i\n",
    "        putStrLn $ \"expected \" ++ show (testLabels !! i)\n",
    "        putStrLn $ \"     got \" ++ show (testPreds V.! i)\n",
    "        \n",
    "-- Ganked from tensorflow-mnist/app/Main.hs\n",
    "reduceMean :: TF.Tensor TF.Build Float -> TF.Tensor TF.Build Float\n",
    "reduceMean xs = TF.mean xs (TF.scalar (0 :: Int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training error 74.0\n",
       "training error 7.999998\n",
       "training error 5.000001\n",
       "training error 10.000002\n",
       "training error 1.9999981\n",
       "training error 1.9999981\n",
       "training error 2.9999971\n",
       "training error 1.9999981\n",
       "training error 6.0\n",
       "training error 4.000002\n",
       "training error 1.9999981\n",
       "\n",
       "test error 5.1699996\n",
       "\n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "      ▒▓▓▓░░                \n",
       "      ██████████████▓░      \n",
       "      ▒▒▒▒▓██████████▓      \n",
       "           ░▒░▒▒▒░░██▒      \n",
       "                  ▒██░      \n",
       "                 ░██▒       \n",
       "                 ▓██░       \n",
       "                ░██░        \n",
       "                ▓█▓░        \n",
       "               ░██░         \n",
       "               ▒█▓          \n",
       "              ▒██░          \n",
       "             ░██▓           \n",
       "            ░███░           \n",
       "            ░██▒            \n",
       "           ░██▒░            \n",
       "           ▓██░             \n",
       "          ░███░             \n",
       "          ▒███░             \n",
       "          ▒██░              \n",
       "                            \n",
       "\n",
       "\n",
       "expected 7\n",
       "     got 7\n",
       "\n",
       "                            \n",
       "                            \n",
       "                            \n",
       "          ▒▒▓██▓▒           \n",
       "         ▓███████░          \n",
       "        ▓████▓▓██▒          \n",
       "       ░███░░ ░██▓          \n",
       "       ▒██░   ▒██▒          \n",
       "        ░░    ███▒          \n",
       "             ▒███░          \n",
       "            ▒███░           \n",
       "            ▓██▓            \n",
       "           ▓██▓░            \n",
       "          ░███░             \n",
       "          ███▓              \n",
       "         ▒██▓░              \n",
       "        ░███▓               \n",
       "        ▓██▓░               \n",
       "        ███░                \n",
       "        ███░░░░░░ ░░░░▓▓▓▓░ \n",
       "        ████████▓▓▓███████▒ \n",
       "        ▓██████████████▓▒▒░ \n",
       "         ▒▒▒▒▓███▓▒▒░       \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "\n",
       "\n",
       "expected 2\n",
       "     got 2\n",
       "\n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                ░█▒         \n",
       "                ▒█▒         \n",
       "                ▓█          \n",
       "               ░█▓          \n",
       "               ▒█░          \n",
       "               ██░          \n",
       "              ░██           \n",
       "              ▒██           \n",
       "              ▓█▒           \n",
       "             ░██░           \n",
       "             ▒█▓            \n",
       "             ▓█▒            \n",
       "            ░██             \n",
       "            ▒█▓             \n",
       "            ▓█▓             \n",
       "            ██▒             \n",
       "           ░██▒             \n",
       "           ▓██░             \n",
       "          ░██▒              \n",
       "          ░█▓░              \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "\n",
       "\n",
       "expected 1\n",
       "     got 1\n",
       "\n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "            ░▓██░           \n",
       "            ░███▒           \n",
       "           ░████▒           \n",
       "          ▒▓████▓▒░         \n",
       "          █████████░        \n",
       "         ▓██████████        \n",
       "        ░█████▓▒░▓██▒       \n",
       "       ░█████▓░  ░███▒░     \n",
       "       ░███▓░     ▒███░     \n",
       "       ░███░      ░███░     \n",
       "       ░██        ░███▓     \n",
       "       ▓██        ▒███░     \n",
       "       ███      ░░████░     \n",
       "       ███      ▓████░      \n",
       "       ███     ▓████▓       \n",
       "       ███▒▒████████        \n",
       "       ▒███████████▓        \n",
       "       ░█████████▓░░        \n",
       "        ░▓██████▒           \n",
       "          ▒▓█▓▒▒░           \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "                            \n",
       "\n",
       "\n",
       "expected 0\n",
       "     got 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "version": "8.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
